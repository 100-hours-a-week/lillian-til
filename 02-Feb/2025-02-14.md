## 날짜: 2025-02-14

### 스크럼
- 학습 목표 1: 데이터 전처리 과정과 데이터 품질 향상 방법 학습
- 학습 목표 2: 정형 데이터와 비정형 데이터 처리 기술의 차이 이해
- 학습 목표 3: SciPy를 활용한 기본 통계 분석 방법 익히기
- 학습 목표 4: 시각화 도구를 활용한 데이터 전달 방법 학습
- 학습 목표 5: 시계열 데이터 분석 기법의 중요성 이해
- 학습 목표 6: 데이터 리모델링 패키지를 활용한 데이터 변환 및 집계 방법 학습

### 새로 배운 내용
#### 주제 1: 데이터 전처리와 품질 향상 방법
- 데이터 전처리는 결측치와 이상치 제거, 데이터 정제를 통해 분석 결과의 신뢰성을 높이는 필수 과정입니다.
- 데이터의 복잡성을 줄이고 계산 효율성을 높이기 위해 데이터 표준화 및 변환 과정을 수행합니다.
- 주요 전처리 기법으로는 결측치 대체, 이상치 처리, 데이터 정규화 등이 있습니다.

#### 주제 2: 정형 데이터와 비정형 데이터 처리 기술
- **정형 데이터**는 RDBMS에 저장되며, Pandas를 활용한 데이터 전처리 및 자동화가 중요합니다. 예: 금융 데이터 분석.
- **비정형 데이터**는 JSON, YAML 등으로 구성되며, 데이터 정제(re.sub 활용)와 API 처리가 필수입니다. 예: 로그 데이터 처리 및 머신러닝 모델 설정.

#### 주제 3: SciPy를 활용한 기본 통계 분석
- SciPy는 데이터의 중심 경향, 분포, 상관관계, 가설 검정 등을 분석하여 데이터 특성을 파악하는 데 도움을 줍니다.
- 주요 활용 사례: 정규성 검정, 회귀 분석, 분산 분석.

#### 주제 4: 시각화 도구를 활용한 데이터 통찰 전달
- 복잡한 데이터를 히스토그램, 막대 그래프 등으로 시각화하여 전달력을 높입니다.
- 시각화는 데이터의 패턴과 추세를 직관적으로 표현하여 초보자도 데이터의 의미를 쉽게 이해할 수 있게 합니다.

#### 주제 5: 시계열 데이터 분석의 중요성
- 시계열 데이터는 시간의 흐름에 따라 데이터를 분류하고 패턴을 분석하여 계절성, 트렌드, 이상치를 탐지할 수 있습니다.
- ARIMA와 같은 모델을 통해 시계열 예측이 가능하며, 이동평균기법으로 추세 흐름을 파악할 수 있습니다.

#### 주제 6: 데이터 리모델링 패키지를 활용한 데이터 변환 및 집계 방법
- 데이터 리모델링은 데이터를 분석하기 쉬운 형태로 변환하여 품질을 향상시키고 효율성을 높이는 과정입니다.
- 데이터 변환: 데이터를 원하는 형태와 구조로 변경.
- 데이터 집계: 통계적 계산과 요약을 통해 데이터의 핵심 정보를 도출.
- 데이터 정제: 결측값 처리, 중복값 제거로 데이터 신뢰성을 강화.

### 오늘의 도전 과제와 해결 방법
- 딥다이브

### 오늘의 회고
- 오늘 학습을 통해 데이터 전처리와 시각화의 중요성을 다시금 깨달았습니다. 특히 비정형 데이터 처리와 YAML 설정 파일 사용은 실무적으로 매우 유용할 것 같습니다.
- SciPy를 통한 정규성 검정과 가설 검정 실습에서 일부 오류를 겪었으나, 문제 해결 과정을 통해 이해를 더 깊게 할 수 있었습니다.

### 참고 자료 및 링크
- [15지조? 홈페이지](https://www.notion.so/adapterz/15-15-6c7ce2c02bfa44cc9972a038ba667e28?pvs=4)
