## 날짜: 2025-03-11  

### 스크럼  
- LangChain의 개념과 활용 방법 학습  
- 임베딩 및 유사도 검색(Similarity Search) 이해  
- FAISS와 RAG(Retrieval-Augmented Generation) 개념 정리  
- Transformer 모델의 주요 파라미터 분석  

### 새로 배운 내용  
#### LangChain 개요  
- 대형 언어 모델(LLM)과 외부 데이터 소스를 효과적으로 연결하는 프레임워크  
- 문서 검색, 질의응답, 대화형 AI 등에 활용 가능  

#### 텍스트 데이터와 임베딩(Embedding)  
- 텍스트 데이터를 수치화하여 벡터 공간에서 유사도 비교 가능  
- 단어 임베딩(Word Embedding)과 문서 임베딩(Document Embedding)으로 구분됨  

#### FAISS(Facebook AI Similarity Search)  
- 대량의 벡터 데이터를 빠르게 검색하는 라이브러리  
- 효율적인 유사도 검색을 위해 널리 사용됨  

#### 유사도 검색(Similarity Search)  
- 사용자의 질의(Query)와 가장 유사한 문서를 검색하는 방법  
- 벡터 임베딩을 활용하여 의미적 유사도를 비교  

#### RAG(Retrieval-Augmented Generation)  
- LLM과 검색 시스템을 결합하여 보다 정확하고 신뢰할 수 있는 정보를 제공  
- 단순한 LLM 기반 생성보다 사실적인 응답을 생성 가능  

#### LLMChain  
- LangChain에서 LLM을 체인 형태로 연결하여 다단계 응답을 생성하는 방식  
- 여러 데이터 소스를 활용한 응답 생성 가능  

#### 트랜스포머 모델 파라미터  
- **인코딩 & 디코딩**: 입력 데이터를 벡터화하고, 최종 출력을 생성하는 과정  
- **어텐션(Attention)**: 중요한 정보에 집중하는 메커니즘  
- **피드 포워드(Feed Forward)**: 어텐션 레이어를 통과한 데이터를 변환하는 신경망  

#### AI 애플리케이션의 기술 스택  
- **파이토치**: LLM 및 딥러닝 모델 학습을 위한 기반 프레임워크  
- **랭체인**: 검색 기반 LLM 애플리케이션을 위한 RAG 프레임워크  
- **허깅페이스**: 트랜스포머 모델 및 사전 학습 모델 관리  

### 기타
### 프로젝트 역할 분담 예시  
- **AI 개발자(엔지니어)**: 모델을 활용하여 LangChain으로 LLM 애플리케이션을 구현  
- **AI 모델러(리서처, 디자이너, 아키텍트, 설계자)**: 모델 설계, 학습, 미세 조정 수행  

### TMI  
- **fetch, retrieve**: 조회(검색) 및 데이터 읽기  
- **위치 벡터**: 원점이 시점인 벡터  
- **컴퓨터는 수학의 구현이다**: 알고리즘과 데이터 구조가 수학적 원리에 기반함  
- **seq2seq(sequence to sequence)**: 텍스트 변환 태스크(번역, 요약 등)의 기본 구조  
- **Embedding vs Imbedding(발음 임베딩)**: 두 표현 모두 사용 가능  

### 오늘의 회고  
- LangChain이 LLM을 보다 실용적으로 활용하는 데 중요한 역할을 한다는 점을 배웠다.  
- FAISS를 통해 대량의 데이터에서 유사도를 비교하는 개념을 이해할 수 있었다.  
- RAG 기법이 단순한 LLM 응답보다 더 신뢰할 수 있는 정보를 제공하는 방식이라는 점이 인상적이었다.  
- 트랜스포머 모델의 구조를 다시 정리하면서 어텐션과 피드 포워드의 역할을 명확히 이해할 수 있었다.  

### 참고 자료 및 링크  
- [LangChain 공식 문서](https://python.langchain.com/)  
- [FAISS 공식 문서](https://faiss.ai/)  
- [RAG 개념 설명](https://huggingface.co/blog/retrieval-augmented-generation)  
