## 날짜: 2025-03-05

### 스크럼  
- 조기 종료(Early Stopping) 기법 이해  
- 하이퍼파라미터 최적화 방법 학습  

### 새로 배운 내용  
#### 조기 종료(Early Stopping)  
- 모델이 과적합하는 것을 방지하기 위해 검증 데이터 성능을 모니터링하여 학습을 조기에 종료하는 기법  
- 특정 에포크 이후 검증 성능이 개선되지 않으면 학습을 멈춤  
- 일반적으로 검증 손실(Validation Loss)을 기준으로 판단  

#### 하이퍼파라미터(Hyperparameter)  
- 모델이 학습하는 동안 조정되지 않는 설정 값으로, 성능에 큰 영향을 미침  
- 주요 하이퍼파라미터: 학습률(Learning Rate), 배치 크기(Batch Size), 드롭아웃(Dropout), 가중치 초기화 방법 등  
- 최적의 값을 찾기 위해 Grid Search, Random Search, Bayesian Optimization 등의 기법 사용  

### 추가 미션  
- **미션 1:** 조기 종료를 적용하여 과적합 방지 효과 실험  
  - 조기 종료를 적용한 모델과 적용하지 않은 모델의 성능 비교  
- **미션 2:** 하이퍼파라미터 튜닝을 통해 모델 성능 최적화  
  - 학습률과 배치 크기를 변경하며 성능 변화를 분석  

### 오늘의 회고  
- 조기 종료가 과적합을 방지하는 중요한 기법이라는 것을 실습하며 이해할 수 있었다.  
- 하이퍼파라미터 최적화가 모델 성능에 미치는 영향을 직접 실험해볼 수 있었다.  
- 앞으로 Bayesian Optimization을 활용한 고급 하이퍼파라미터 튜닝 기법도 연구해봐야겠다.  

### 참고 자료 및 링크  
- [Early Stopping 개념](https://en.wikipedia.org/wiki/Early_stopping)  
- [Hyperparameter Optimization 기법](https://en.wikipedia.org/wiki/Hyperparameter_optimization)  
